{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6dc51cef-b78b-499c-9862-cb838ae6dae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler\n",
    "from pyspark.ml.classification import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19aa50b6-4b05-4959-a3cc-f632452df250",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Pipeline\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f9308f1-4b85-4647-a4c0-e22856c1925b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = spark.read.option(\"header\",True).option(\"inferSchema\",True).csv(\"dados_regressao_cor.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f8608c8-5b05-4d32-8c57-95c81b826d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+------------------+------------------+\n",
      "|     cor|                x1|                x2|                 y|\n",
      "+--------+------------------+------------------+------------------+\n",
      "|   verde| 3.745401188473625|3.7364081846669848| 12.30060447765728|\n",
      "|    azul|  9.50714306409916|3.3291209623140325|11.757695314234958|\n",
      "|    azul| 7.319939418114051|1.7615391250286005| 9.506989456356553|\n",
      "|   verde| 5.986584841970366|  6.07266670101488|19.769172200123297|\n",
      "|vermelho|1.5601864044243652| 4.766241605086289| 7.215801339758797|\n",
      "+--------+------------------+------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dados.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f1c0ca5-598c-4b42-8f5c-6995fa2f9004",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexador_label = StringIndexer(inputCol=\"cor\",outputCol=\"label\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8310ecff-ee9b-433d-a93b-c1ebdfdf4c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=[\"x1\",\"x2\", \"y\"], outputCol=\"features_raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ba5223e-83e3-4ea5-a7bf-d19abf2565a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(inputCol=\"features_raw\",outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0e8058d-0da3-483d-a4d3-31e4f02f35e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(featuresCol=\"features\",labelCol=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf59d693-8ee9-4670-886e-c36956a0d03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2edbbbfd-067a-48a9-aad8-41cc223f1f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[indexador_label,assembler,scaler,lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a96a845-d113-4681-a509-bb3b62c1f424",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam,[0.01,0.1]) \\\n",
    "    .addGrid(lr.elasticNetParam,[0.0,0.5,1.0]) \\\n",
    "    .build()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8fe77d0d-0e4c-41b6-a354-2988a2f00dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fbbee008-884e-4674-854c-6d370b5486ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator\n",
    "\n",
    "validador = validador = CrossValidator(\n",
    "    estimator=pipeline,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=3,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b692d491-e25d-4fd5-b2b7-0450048f9e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_cv = validador.fit(dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0ed6e85f-35f2-4b2c-b85e-854db15c4865",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = modelo_cv.transform(dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d7dc2a6f-1efa-4181-aa37-deb58039bf67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+------------------+------------------+----------+\n",
      "|     cor|                x1|                x2|                 y|prediction|\n",
      "+--------+------------------+------------------+------------------+----------+\n",
      "|   verde| 3.745401188473625|3.7364081846669848| 12.30060447765728|       0.0|\n",
      "|    azul|  9.50714306409916|3.3291209623140325|11.757695314234958|       2.0|\n",
      "|    azul| 7.319939418114051|1.7615391250286005| 9.506989456356553|       2.0|\n",
      "|   verde| 5.986584841970366|  6.07266670101488|19.769172200123297|       0.0|\n",
      "|vermelho|1.5601864044243652| 4.766241605086289| 7.215801339758797|       0.0|\n",
      "+--------+------------------+------------------+------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resultado.select(\"cor\", \"x1\",\"x2\", \"y\", \"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8114dbfd-9dce-42e1-b6a6-da521f455386",
   "metadata": {},
   "outputs": [],
   "source": [
    "acuracia = evaluator.evaluate(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b670bd5d-e08e-40e5-a4cb-28fd41395de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8873\n"
     ]
    }
   ],
   "source": [
    "print(acuracia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "672e6e32-712b-42b3-a767-802532f2d43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_cv.write().overwrite().save(\"modelos/pipeline_classificacao\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2147630e-4ae2-47c0-a578-9fa6be38c4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidatorModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c1c7c331-ca6c-4023-a1a9-1d50fd42ec56",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_carregado = CrossValidatorModel.load(\"modelos/pipeline_classificacao\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7e6f937-0d73-415b-99e1-1ed5ce230d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "novo_dado = spark.createDataFrame([\n",
    "    Row(cor=\"azul\", x1=4.32,x2=5.7,y=10.3)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8f8025b3-a7ad-41e1-9526-6cc6256e09b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "previsao = modelo_carregado.transform(novo_dado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d924f34d-b3c5-4311-8582-e864b6e8f132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+---+----+-----+---------------+--------------------+--------------------+--------------------+----------+\n",
      "| cor|  x1| x2|   y|label|   features_raw|            features|       rawPrediction|         probability|prediction|\n",
      "+----+----+---+----+-----+---------------+--------------------+--------------------+--------------------+----------+\n",
      "|azul|4.32|5.7|10.3|  2.0|[4.32,5.7,10.3]|[1.50192890159389...|[-2.1126177117169...|[0.07876847205812...|       1.0|\n",
      "+----+----+---+----+-----+---------------+--------------------+--------------------+--------------------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception occurred during processing of request from ('127.0.0.1', 35334)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/opt/conda/lib/python3.11/socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/opt/conda/lib/python3.11/socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/opt/conda/lib/python3.11/socketserver.py\", line 755, in __init__\n",
      "    self.handle()\n",
      "  File \"/usr/local/spark/python/pyspark/accumulators.py\", line 295, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/usr/local/spark/python/pyspark/accumulators.py\", line 267, in poll\n",
      "    if self.rfile in r and func():\n",
      "                           ^^^^^^\n",
      "  File \"/usr/local/spark/python/pyspark/accumulators.py\", line 271, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/spark/python/pyspark/serializers.py\", line 596, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "previsao.show(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
